# ğŸŒ³ RAPTOR Production Suite

<div align="center">

![RAPTOR Logo](https://img.shields.io/badge/RAPTOR-Production%20Ready-green?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python)
![Docker](https://img.shields.io/badge/Docker-Ready-blue?style=for-the-badge&logo=docker)
![Production](https://img.shields.io/badge/Production-Enterprise--Grade-red?style=for-the-badge)

**Enterprise-Level RAG Sistemi - Tam Otomatik Production Deployment**

[ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§) â€¢ [ğŸ“– DetaylÄ± Kurulum](#-detaylÄ±-kurulum-rehberi) â€¢ [ğŸ”§ Configuration](#ï¸-configuration-yÃ¶netimi) â€¢ [ğŸ“Š Monitoring](#-monitoring--metrics) â€¢ [â“ FAQ](#-sÄ±kÃ§a-sorulan-sorular)

</div>

---

## ğŸ“‹ Ä°Ã§indekiler

- [ğŸ¯ Proje HakkÄ±nda](#-proje-hakkÄ±nda)
- [â­ Ã–zellikler](#-Ã¶zellikler)
- [ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (5 Dakika)](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§-5-dakika)
- [ğŸ“ Dosya YapÄ±sÄ±](#-dosya-yapÄ±sÄ±)
- [ğŸ“– DetaylÄ± Kurulum Rehberi](#-detaylÄ±-kurulum-rehberi)
- [ğŸ”§ Configuration YÃ¶netimi](#ï¸-configuration-yÃ¶netimi)
- [ğŸ³ Docker Deployment](#-docker-deployment)
- [ğŸ“Š Monitoring & Metrics](#-monitoring--metrics)
- [âš¡ Performance Optimization](#-performance-optimization)
- [ğŸ› ï¸ Troubleshooting](#ï¸-troubleshooting)
- [â“ SÄ±kÃ§a Sorulan Sorular](#-sÄ±kÃ§a-sorulan-sorular)

---

## ğŸ¯ Proje HakkÄ±nda

**RAPTOR Production Suite**, Stanford'Ä±n RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) yaklaÅŸÄ±mÄ±nÄ±n **enterprise-grade production** implementasyonudur.

### ğŸ¤” Ne Ä°ÅŸe Yarar?

1. **DÃ¶kÃ¼manlarÄ±nÄ±zÄ±** hierarchical tree yapÄ±sÄ±nda organize eder
2. **AkÄ±llÄ± soru-cevap sistemi** sunar (WebSocket tabanlÄ±)
3. **Production ortamÄ±nda** gÃ¼venle Ã§alÄ±ÅŸÄ±r
4. **Otomatik monitoring** ve performance optimization saÄŸlar
5. **Scalable ve concurrent** kullanÄ±cÄ±larÄ± destekler

### ğŸ—ï¸ NasÄ±l Ã‡alÄ±ÅŸÄ±r?

```
ğŸ“„ DokÃ¼man â†’ ğŸŒ³ RAPTOR Tree â†’ ğŸ¤– AI Asistan â†’ ğŸ’¬ KullanÄ±cÄ±
    â†“              â†“              â†“             â†“
  Chunks      Hierarchical    Smart RAG    Real-time
            Summarization    Retrieval      Chat
```

---

## â­ Ã–zellikler

### ğŸš€ **Core Features**
- âœ… **Hierarchical RAG**: Multi-layer document understanding
- âœ… **Real-time Chat**: WebSocket-based streaming responses
- âœ… **Semantic Search**: Advanced embedding-based retrieval
- âœ… **Smart Caching**: 80%+ performance improvement
- âœ… **Async Processing**: 10x faster than traditional approaches

### ğŸ¢ **Enterprise Features**
- âœ… **Auto-scaling Configuration**: Resource-based optimization
- âœ… **Environment Management**: Dev/Staging/Production configs
- âœ… **Health Monitoring**: Real-time system health checks
- âœ… **Performance Analytics**: Comprehensive metrics & dashboards
- âœ… **Docker Containerization**: One-click deployment
- âœ… **Load Testing**: Built-in stress testing & optimization

### ğŸ“Š **Monitoring & Observability**
- âœ… **Prometheus Metrics**: Custom RAPTOR metrics collection
- âœ… **Grafana Dashboards**: Pre-built visualization dashboards
- âœ… **Health Checks**: Automated system health monitoring
- âœ… **Performance Profiling**: Auto-optimization recommendations
- âœ… **Error Tracking**: Comprehensive error logging & alerting

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (5 Dakika)

### 1ï¸âƒ£ **Ã–nkoÅŸullar**
```bash
# Python 3.8+ gerekli
python --version

# Docker & Docker Compose (opsiyonel ama Ã¶nerilen)
docker --version
docker-compose --version
```

### 2ï¸âƒ£ **Projeyi Kur**
```bash
# Repository'yi indir
git clone <your-repo-url>
cd raptor-production

# Python environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Dependencies
pip install -r requirements.txt
```

### 3ï¸âƒ£ **Environment Setup**
```bash
# .env dosyasÄ± oluÅŸtur
cp .env.example .env

# OpenAI API key'ini ekle
nano .env  # veya herhangi bir editor
```

`.env` dosyasÄ±nda:
```env
OPENAI_API_KEY=sk-your-actual-openai-key-here
REDIS_PASSWORD=gÃ¼Ã§lÃ¼-ÅŸifre-buraya
GRAFANA_PASSWORD=admin-ÅŸifre-buraya
```

### 4ï¸âƒ£ **RAPTOR Tree OluÅŸtur**
```bash
# DokÃ¼manÄ±nÄ± hazÄ±rla
echo "Bu bir test dÃ¶kÃ¼mandÄ±r. RAPTOR bu metni analiz edecek." > data.txt

# Tree'yi oluÅŸtur (otomatik optimizasyon ile)
python build-raptor-production.py data.txt
```

### 5ï¸âƒ£ **Production'a Deploy Et**
```bash
# Script'i Ã§alÄ±ÅŸtÄ±rÄ±labilir yap
chmod +x scripts/deploy.sh

# Tek komut ile production deployment
./scripts/deploy.sh
```

### 6ï¸âƒ£ **Test Et**
```bash
# Health check
curl http://localhost:8000/health

# Web arayÃ¼zlerini aÃ§
open http://localhost:8000      # RAPTOR API
open http://localhost:3000      # Grafana Dashboard (admin/admin)
open http://localhost:9090      # Prometheus Metrics
```

ğŸ‰ **Tebrikler!** RAPTOR sisteminiz production'da Ã§alÄ±ÅŸÄ±yor!

---

## ğŸ“ Dosya YapÄ±sÄ±

```
raptor-production/
â”œâ”€â”€ ğŸ“œ TEMEL DOSYALAR
â”‚   â”œâ”€â”€ README.md                       # Bu dosya
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚   â”œâ”€â”€ .env.example                    # Environment template
â”‚   â””â”€â”€ data.txt                        # Ã–rnek dokÃ¼man
â”‚
â”œâ”€â”€ ğŸš€ CORE SCRIPTS
â”‚   â”œâ”€â”€ generic-qa-server.py            # Ana WebSocket sunucu
â”‚   â”œâ”€â”€ build-raptor-production.py      # Enterprise tree builder
â”‚   â”œâ”€â”€ production-config.py            # Configuration manager
â”‚   â”œâ”€â”€ monitoring-setup.py             # Monitoring infrastructure
â”‚   â”œâ”€â”€ deploy-raptor-production.py     # Production deployer
â”‚   â””â”€â”€ performance-optimizer.py        # Load testing & optimization
â”‚
â”œâ”€â”€ ğŸ³ DOCKER & DEPLOYMENT
â”‚   â”œâ”€â”€ Dockerfile                      # Multi-stage production image
â”‚   â”œâ”€â”€ docker-compose.production.yml   # Production services
â”‚   â”œâ”€â”€ requirements-production.txt     # Production-specific deps
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ deploy.sh                   # Automated deployment script
â”‚       â””â”€â”€ healthcheck.py              # Docker health check
â”‚
â”œâ”€â”€ âš™ï¸ CONFIGURATION
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ development.json            # Dev environment settings
â”‚   â”‚   â”œâ”€â”€ staging.json                # Staging environment settings
â”‚   â”‚   â”œâ”€â”€ production.json             # Production environment settings
â”‚   â”‚   â””â”€â”€ redis.conf                  # Redis configuration
â”‚   â””â”€â”€ .env                            # Environment variables (create this)
â”‚
â”œâ”€â”€ ğŸ“Š MONITORING
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”‚   â””â”€â”€ prometheus.yml          # Metrics collection config
â”‚   â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”‚   â””â”€â”€ raptor_dashboard.json   # Pre-built dashboard
â”‚   â”‚   â””â”€â”€ docker-compose.yml          # Monitoring stack
â”‚   â””â”€â”€ nginx/
â”‚       â””â”€â”€ nginx.conf                  # Load balancer config
â”‚
â”œâ”€â”€ ğŸŒ³ RAPTOR TREE (otomatik oluÅŸacak)
â”‚   â””â”€â”€ vectordb/
â”‚       â”œâ”€â”€ raptor-optimized            # Built tree file
â”‚       â””â”€â”€ raptor-optimized_metrics.json # Build metrics
â”‚
â””â”€â”€ ğŸ“ LOGS & METRICS (otomatik oluÅŸacak)
    â”œâ”€â”€ logs/                           # Application logs
    â”œâ”€â”€ metrics/                        # Performance metrics
    â””â”€â”€ deployment_log_*.json           # Deployment history
```

---

## ğŸ“– DetaylÄ± Kurulum Rehberi

### ğŸ”§ **1. Sistem Gereksinimleri**

#### **Minimum Gereksinimler:**
- **CPU**: 4 cores
- **RAM**: 8GB
- **Disk**: 50GB free space
- **OS**: Linux, macOS, Windows
- **Python**: 3.8+

#### **Ã–nerilen Gereksinimler (Production):**
- **CPU**: 8+ cores
- **RAM**: 16GB+
- **Disk**: 100GB+ SSD
- **Network**: Stable internet connection

#### **Software Dependencies:**
```bash
# Python packages (otomatik yÃ¼klenecek)
pip install -r requirements.txt

# System packages (Ubuntu/Debian)
sudo apt update
sudo apt install -y curl build-essential

# System packages (CentOS/RHEL)
sudo yum update
sudo yum install -y curl gcc gcc-c++

# macOS (Homebrew)
brew install curl
```

### ğŸ”‘ **2. API Key Setup**

#### **OpenAI API Key:**
1. [OpenAI Platform](https://platform.openai.com/api-keys) hesabÄ± oluÅŸtur
2. API key oluÅŸtur
3. `.env` dosyasÄ±na ekle:

```env
OPENAI_API_KEY=sk-proj-your-actual-key-here
```

#### **DiÄŸer Opsiyonel Ayarlar:**
```env
# Redis gÃ¼venlik (Ã¶nerilen)
REDIS_PASSWORD=super-gÃ¼Ã§lÃ¼-ÅŸifre-123

# Grafana admin ÅŸifresi
GRAFANA_PASSWORD=admin-ÅŸifre-456

# Performance tuning
RAPTOR_BATCH_SIZE=150
MAX_CONCURRENT_OPERATIONS=12
```

### ğŸ“„ **3. DokÃ¼man HazÄ±rlama**

#### **Desteklenen Formatlar:**
- **Plain Text**: `.txt` dosyalarÄ±
- **Markdown**: `.md` dosyalarÄ±
- **Rich Text**: FormatlanmÄ±ÅŸ metinler

#### **DokÃ¼man Ã–rnekleri:**

```bash
# Basit metin dosyasÄ±
echo "Åirketimiz 2020'de kuruldu. Ana hizmetimiz web geliÅŸtirmedir." > data.txt

# Daha karmaÅŸÄ±k dokÃ¼man
cat > data.txt << 'EOF'
# Åirket HakkÄ±nda

## TarihÃ§e
Åirketimiz 2020 yÄ±lÄ±nda Ä°stanbul'da kurulmuÅŸtur.

## Hizmetlerimiz
- Web geliÅŸtirme
- Mobil uygulama
- AI Ã§Ã¶zÃ¼mleri

## Ä°letiÅŸim
Email: info@sirket.com
Telefon: +90 212 123 45 67
EOF
```

### ğŸŒ³ **4. RAPTOR Tree Building**

#### **Temel Build:**
```bash
python build-raptor-production.py data.txt
```

#### **Advanced Build Options:**
```bash
# Performance profili ile
python build-raptor-production.py data.txt --profile speed

# Custom output path
python build-raptor-production.py data.txt --output vectordb/custom-tree

# Force rebuild
python build-raptor-production.py data.txt --force

# Verbose logging
python build-raptor-production.py data.txt --log-level DEBUG
```

#### **Performance Profiles:**

| Profile | HÄ±z | Kalite | Bellek | KullanÄ±m AlanÄ± |
|---------|-----|--------|--------|----------------|
| `speed` | â­â­â­ | â­â­ | â­â­ | Real-time chat |
| `balanced` | â­â­ | â­â­â­ | â­â­ | General purpose |
| `quality` | â­ | â­â­â­ | â­ | Research, analysis |
| `memory` | â­â­ | â­â­ | â­â­â­ | Limited resources |

### ğŸš€ **5. Deployment Options**

#### **Option A: Docker Deployment (Ã–nerilen)**
```bash
# Tek komut deployment
chmod +x scripts/deploy.sh
./scripts/deploy.sh
```

#### **Option B: Manuel Python Deployment**
```bash
# Production server baÅŸlat
python deploy-raptor-production.py --env production

# Development server baÅŸlat
python generic-qa-server.py
```

#### **Option C: Kubernetes Deployment**
```bash
# Helm chart ile (geliÅŸmiÅŸ kullanÄ±cÄ±lar iÃ§in)
helm install raptor ./kubernetes/helm-chart
```

---

## ğŸ”§ Configuration YÃ¶netimi

### ğŸ“ **Environment Configurations**

#### **Development (development.json):**
```json
{
  "raptor": {
    "batch_size": 50,
    "num_layers": 3,
    "enable_metrics": false
  },
  "workers": 1,
  "monitoring": {
    "enable_prometheus": false,
    "log_level": "DEBUG"
  }
}
```

#### **Production (production.json):**
```json
{
  "raptor": {
    "batch_size": 150,
    "num_layers": 5,
    "max_concurrent_operations": 12,
    "cache_ttl": 7200
  },
  "workers": 4,
  "monitoring": {
    "enable_prometheus": true,
    "log_level": "INFO"
  }
}
```

### âš™ï¸ **Configuration Management**

#### **Otomatik Environment Detection:**
```python
from production_config import get_production_config

# Otomatik environment detection (RAPTOR_ENV env var'dan)
config = get_production_config()

# Manuel environment
config = get_production_config("production", "speed")
```

#### **Runtime Configuration Override:**
```python
config = get_production_config()
config.raptor.batch_size = 200  # Override specific settings
config.workers = 8
```

#### **Environment Variables:**
```bash
# Environment control
export RAPTOR_ENV=production
export RAPTOR_PROFILE=speed

# Performance tuning
export RAPTOR_BATCH_SIZE=200
export MAX_WORKERS=8

# Redis settings
export REDIS_HOST=localhost
export REDIS_PORT=6379
export REDIS_PASSWORD=your-password
```

---

## ğŸ³ Docker Deployment

### ğŸš¢ **Docker Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Nginx       â”‚   â”‚   RAPTOR App    â”‚   â”‚     Redis       â”‚
â”‚ (Load Balancer) â”‚â”€â”€â–¶â”‚  (Python App)   â”‚â”€â”€â–¶â”‚    (Cache)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Prometheus    â”‚   â”‚    Grafana      â”‚
                    â”‚   (Metrics)     â”‚   â”‚ (Dashboards)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“‹ **Services**

| Service | Port | Purpose | Health Check |
|---------|------|---------|--------------|
| `raptor-app` | 8000 | Main application | `/health` |
| `redis` | 6379 | Caching layer | `redis-cli ping` |
| `prometheus` | 9090 | Metrics collection | `/-/healthy` |
| `grafana` | 3000 | Dashboards | `/api/health` |
| `nginx` | 80/443 | Load balancer | HTTP response |

### ğŸ› ï¸ **Docker Commands**

#### **Basic Operations:**
```bash
# Deploy all services
./scripts/deploy.sh

# View service status
docker-compose -f docker-compose.production.yml ps

# View logs
docker-compose -f docker-compose.production.yml logs -f raptor-app

# Scale services
docker-compose -f docker-compose.production.yml scale raptor-app=3

# Stop services
docker-compose -f docker-compose.production.yml down

# Full cleanup
./scripts/deploy.sh --cleanup
```

#### **Development Mode:**
```bash
# Development deployment
./scripts/deploy.sh --env development

# Local development (no Docker)
python generic-qa-server.py
```

#### **Troubleshooting:**
```bash
# Check container health
docker ps
docker inspect raptor-app

# Enter container for debugging
docker exec -it raptor-app bash

# Check resource usage
docker stats

# View detailed logs
docker-compose logs --timestamps raptor-app
```

---

## ğŸ“Š Monitoring & Metrics

### ğŸ“ˆ **Prometheus Metrics**

#### **RAPTOR-Specific Metrics:**
```promql
# Query performance
raptor_retrieval_duration_seconds

# Cache efficiency
rate(raptor_cache_operations_total{result="hit"}[5m]) / 
rate(raptor_cache_operations_total[5m])

# Error rate
rate(raptor_errors_total[5m])

# Active connections
raptor_active_connections

# Request throughput
rate(raptor_requests_total[5m])
```

#### **System Metrics:**
```promql
# Memory usage
raptor_memory_usage_bytes

# CPU usage
rate(process_cpu_seconds_total[5m])

# Response time percentiles
histogram_quantile(0.95, rate(raptor_request_duration_seconds_bucket[5m]))
```

### ğŸ“Š **Grafana Dashboards**

#### **Main Dashboard Panels:**
1. **Overview Panel**
   - Request rate
   - Success rate
   - Average response time
   - Active connections

2. **Performance Panel**
   - Response time percentiles (50th, 95th, 99th)
   - Throughput trends
   - Cache hit rates

3. **System Resources**
   - Memory usage
   - CPU usage
   - Disk I/O
   - Network traffic

4. **Error Tracking**
   - Error rates by type
   - Failed requests
   - Timeout incidents

#### **Dashboard Access:**
```bash
# Grafana dashboard
open http://localhost:3000
# Login: admin / admin (or your GRAFANA_PASSWORD)

# Prometheus raw metrics
open http://localhost:9090

# RAPTOR health
curl http://localhost:8000/health | jq
```

### ğŸš¨ **Alerting**

#### **Critical Alerts:**
- Error rate > 5%
- Response time > 10 seconds
- Memory usage > 90%
- Cache hit rate < 50%

#### **Warning Alerts:**
- Response time > 5 seconds
- Memory usage > 80%
- Disk space < 10%

---

## âš¡ Performance Optimization

### ğŸ§ª **Load Testing**

#### **Automatic Load Testing:**
```bash
# Comprehensive load test with auto-optimization
python performance-optimizer.py --optimize

# Custom load test
python performance-optimizer.py \
    --server-url http://localhost:8000 \
    --websocket-url ws://localhost:8000/ws/test \
    --output results.json
```

#### **Load Test Results:**
```json
{
  "tests": {
    "websocket": {
      "success_rate_percent": 98.5,
      "avg_response_time_ms": 1250,
      "total_requests": 500,
      "requests_per_second": 15.2
    }
  },
  "analysis": {
    "performance_grade": "B",
    "recommendations": [
      "Enable early termination",
      "Increase batch size"
    ]
  }
}
```

### ğŸ¯ **Performance Tuning**

#### **Configuration Parameters:**

| Parameter | Low Load | Medium Load | High Load |
|-----------|----------|-------------|-----------|
| `batch_size` | 50 | 100 | 200 |
| `max_concurrent` | 4 | 8 | 16 |
| `workers` | 2 | 4 | 8 |
| `cache_ttl` | 1800 | 3600 | 7200 |

#### **Auto-Optimization:**
```python
# Sistem otomatik olarak yÃ¼k testine gÃ¶re config oluÅŸturur
from performance_optimizer import optimize_production_config

# Mevcut config'i yÃ¼k testi sonuÃ§larÄ±na gÃ¶re optimize et
optimized_config = optimize_production_config(
    test_results="performance_results.json"
)
```

### ğŸ“Š **Performance Monitoring**

#### **Real-time Performance:**
```bash
# Current performance stats
curl http://localhost:8000/metrics | grep raptor_

# Health status with performance data
curl http://localhost:8000/health | jq '.performance'
```

#### **Performance History:**
```python
# Python'da performance geÃ§miÅŸini analiz et
from monitoring_setup import RAPTORMetrics

metrics = RAPTORMetrics()
stats = metrics.get_performance_history(days=7)
```

---

## ğŸ› ï¸ Troubleshooting

### ğŸš¨ **YaygÄ±n Problemler ve Ã‡Ã¶zÃ¼mleri**

#### **1. RAPTOR Tree YÃ¼klenemedi**
```bash
# Problem: "Tree file not found" hatasÄ±
# Ã‡Ã¶zÃ¼m: Tree'yi yeniden build et
python build-raptor-production.py data.txt --force
```

#### **2. Redis BaÄŸlantÄ± HatasÄ±**
```bash
# Problem: Redis connection failed
# Ã‡Ã¶zÃ¼m 1: Redis'i yeniden baÅŸlat
docker-compose restart redis

# Ã‡Ã¶zÃ¼m 2: Redis ÅŸifresini kontrol et
echo "REDIS_PASSWORD=your-password" >> .env
```

#### **3. YavaÅŸ Response Time**
```bash
# Problem: Response time > 5 seconds
# Ã‡Ã¶zÃ¼m: Performance profile deÄŸiÅŸtir
python deploy-raptor-production.py --env production --profile speed

# Veya manuel optimizasyon
python performance-optimizer.py --optimize
```

#### **4. Memory HatasÄ±**
```bash
# Problem: Out of memory
# Ã‡Ã¶zÃ¼m: Memory profile kullan
python deploy-raptor-production.py --env production --profile memory

# Veya Docker resource limit'leri ayarla
docker-compose -f docker-compose.production.yml \
    --compatibility up -d
```

#### **5. OpenAI API Limit**
```bash
# Problem: Rate limit exceeded
# Ã‡Ã¶zÃ¼m: API key ve rate limit ayarlarÄ±nÄ± kontrol et
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
    https://api.openai.com/v1/usage
```

### ğŸ” **Debug Mode**

#### **Application Debug:**
```bash
# Debug logs ile Ã§alÄ±ÅŸtÄ±r
export RAPTOR_LOG_LEVEL=DEBUG
python generic-qa-server.py

# Veya Docker ile
docker-compose -f docker-compose.production.yml \
    -f docker-compose.debug.yml up
```

#### **Performance Debug:**
```python
# Python'da detaylÄ± performance analizi
from generic_qa_server import RA

# Performance summary al
summary = RA.get_performance_summary()
print(json.dumps(summary, indent=2))

# Specific metric'leri kontrol et
retriever_stats = RA.retriever.get_performance_stats()
print(f"Cache hit rate: {retriever_stats['cache_hit_rate']}")
```

### ğŸ“‹ **Log Analysis**

#### **Log Locations:**
```bash
# Application logs
tail -f logs/raptor.log

# Docker logs
docker-compose logs -f raptor-app

# System logs
journalctl -f -u docker
```

#### **Log Filtering:**
```bash
# Error'larÄ± filtrele
docker-compose logs raptor-app | grep ERROR

# Performance metric'leri filtrele
docker-compose logs raptor-app | grep "Performance"

# Specific user'Ä±n activity'sini takip et
docker-compose logs raptor-app | grep "client_123"
```

---

## â“ SÄ±kÃ§a Sorulan Sorular

### ğŸ¤” **Genel Sorular**

#### **S: RAPTOR nedir ve nasÄ±l Ã§alÄ±ÅŸÄ±r?**
**C:** RAPTOR, dÃ¶kÃ¼manlarÄ± hierarchical tree yapÄ±sÄ±nda organize eden advanced RAG sistemidir. Traditional RAG'den farkÄ±, dokÃ¼manÄ± farklÄ± abstraction level'larda Ã¶zetleyerek daha iyi context understanding saÄŸlamasÄ±dÄ±r.

#### **S: Hangi dokÃ¼man boyutlarÄ± desteklenir?**
**C:** 
- **Minimum**: 1KB (birkaÃ§ paragraf)
- **Optimal**: 10KB - 1MB
- **Maximum**: 100MB+ (performance profile'a baÄŸlÄ±)

#### **S: Ne kadar GPU/CPU gÃ¼cÃ¼ gerekir?**
**C:** 
- **Minimum**: 4 CPU cores, 8GB RAM
- **Ã–nerilen**: 8+ CPU cores, 16GB+ RAM
- **GPU**: Opsiyonel (embedding model'leri hÄ±zlandÄ±rÄ±r)

### ğŸ”§ **Teknik Sorular**

#### **S: Multiple dokÃ¼manÄ± nasÄ±l iÅŸlerim?**
**C:**
```python
documents = ["doc1.txt", "doc2.txt", "doc3.txt"]
for doc in documents:
    result = build_raptor_production(
        data_path=doc,
        output_path=f"vectordb/raptor-{Path(doc).stem}"
    )
```

#### **S: Custom embedding model kullanabilir miyim?**
**C:** Evet! `CustomEmbeddingModel` class'Ä±nÄ± inherit ederek kendi model'inizi kullanabilirsiniz:
```python
from raptor.EmbeddingModels import BaseEmbeddingModel

class MyCustomModel(BaseEmbeddingModel):
    def create_embedding(self, text):
        # Your custom implementation
        return embedding_vector
```

#### **S: Production'da scaling nasÄ±l yapÄ±lÄ±r?**
**C:** 
```bash
# Horizontal scaling (Docker)
docker-compose scale raptor-app=3

# Vertical scaling (config)
export MAX_WORKERS=8
export RAPTOR_BATCH_SIZE=200
```

### ğŸš€ **Deployment Sorular**

#### **S: Kubernetes'de deploy edebilir miyim?**
**C:** Evet! Docker image'larÄ± Kubernetes-ready. Helm chart Ã¶rneÄŸi:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: raptor-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: raptor
  template:
    metadata:
      labels:
        app: raptor
    spec:
      containers:
      - name: raptor
        image: raptor:latest
        ports:
        - containerPort: 8000
```

#### **S: CI/CD pipeline'Ä± nasÄ±l kurarÄ±m?**
**C:**
```yaml
# .github/workflows/deploy.yml
name: Deploy RAPTOR
on:
  push:
    branches: [main]
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Deploy
      run: ./scripts/deploy.sh --env production
```

### ğŸ’¡ **Optimization Sorular**

#### **S: Cache performansÄ±nÄ± nasÄ±l artÄ±rÄ±rÄ±m?**
**C:**
```python
# Cache TTL'yi artÄ±r
config.cache_ttl = 7200  # 2 hours

# Cache threshold'u ayarla  
config.tr_enable_caching = True
config.tr_early_termination = True
```

#### **S: Memory kullanÄ±mÄ±nÄ± nasÄ±l azaltÄ±rÄ±m?**
**C:**
```bash
# Memory-optimized profile kullan
python deploy-raptor-production.py --profile memory

# Batch size'Ä± azalt
export RAPTOR_BATCH_SIZE=50
```

### ğŸ”’ **Security Sorular**

#### **S: API key'leri nasÄ±l gÃ¼venli tutarÄ±m?**
**C:**
```bash
# Environment variables kullan
export OPENAI_API_KEY="your-key"

# Veya Docker secrets
echo "your-api-key" | docker secret create openai_key -

# Production'da vault solution kullan
# HashiCorp Vault, AWS Secrets Manager, etc.
```

#### **S: HTTPS nasÄ±l enable ederim?**
**C:**
```nginx
# nginx/nginx.conf
server {
    listen 443 ssl;
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    
    location / {
        proxy_pass http://raptor_backend;
    }
}
```

### ğŸ“ **Support & YardÄ±m**

#### **S: Hata durumunda ne yapmalÄ±yÄ±m?**
**C:**
1. **Health check**: `curl http://localhost:8000/health`
2. **Logs kontrol**: `docker-compose logs raptor-app`
3. **Metrics check**: `curl http://localhost:9090/metrics`
4. **Restart**: `./scripts/deploy.sh --rollback && ./scripts/deploy.sh`

#### **S: Performance issue'leri nasÄ±l debug ederim?**
**C:**
```bash
# Load test Ã§alÄ±ÅŸtÄ±r
python performance-optimizer.py --optimize

# Metrics'leri analiz et
curl http://localhost:8000/metrics | grep raptor_

# Resource usage kontrol et
docker stats raptor-app
```

#### **S: Update nasÄ±l yaparÄ±m?**
**C:**
```bash
# Code update
git pull origin main

# Rebuild & redeploy
./scripts/deploy.sh --clean

# Zero-downtime update (advanced)
docker-compose -f docker-compose.production.yml \
    up -d --scale raptor-app=2 --no-recreate
```

---

## ğŸ¯ Best Practices

### ğŸ—ï¸ **Development Best Practices**
1. **Always test in staging first**
2. **Use environment-specific configs**
3. **Monitor performance metrics**
4. **Keep logs organized**
5. **Regular backup strategy**

### ğŸš€ **Production Best Practices**
1. **Use Docker for deployment**
2. **Enable monitoring & alerting**
3. **Set up auto-scaling**
4. **Implement health checks**
5. **Regular performance optimization**

### ğŸ”’ **Security Best Practices**
1. **Use environment variables for secrets**
2. **Enable HTTPS in production**
3. **Regular security updates**
4. **Monitor access logs**
5. **Implement rate limiting**

---

## ğŸ“ Destek & Ä°letiÅŸim

### ğŸ†˜ **Acil Durumlar**
```bash
# Sistem completely down
./scripts/deploy.sh --rollback

# Emergency scale down
docker-compose scale raptor-app=1

# Complete reset
./scripts/deploy.sh --cleanup
./scripts/deploy.sh
```

### ğŸ“§ **YardÄ±m Almak**
1. **GitHub Issues**: Bug reports ve feature requests
2. **Documentation**: Bu README'yi tekrar okuyun
3. **Health Check**: `curl http://localhost:8000/health`
4. **Logs**: `docker-compose logs raptor-app`

---

<div align="center">

## ğŸ‰ RAPTOR Production Suite ile BaÅŸarÄ±lÄ± Projeler!

**Enterprise-grade RAG sisteminiz hazÄ±r. Production'da gÃ¼venle kullanÄ±n.**

[â­ Star this repo](.) â€¢ [ğŸ› Report Bug](.) â€¢ [ğŸ’¡ Request Feature](.) â€¢ [ğŸ“– Documentation](.)

**Made with â¤ï¸ for Enterprise AI Solutions**

</div>